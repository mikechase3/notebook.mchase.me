# v0.2: Setting up Ollama and WebUI

This project sets up a containerized development environment using Docker to analyze large language model (LLM) behavior. The primary goal is to conduct scripted, repeatable experiments by sending prompts to a locally-hosted LLM (via Ollama), capturing results, and preapring the data for analysis.&#x20;

## Background & Core Concepts

Step 1: Create a README w/ what we're doing. Something like:

The environment is orchestrated using docker compose & consists of three main services:

1. **Ollama**: the core service running/serving the open-source LLMs
2. **OpenWebUI**: a friendly user interface for manually interacting with models, pulling new models, and general testing.
3. **Python Env**: `python-dev` is a custom container meant to do automation tasks like batch processing of LLM queries/responses. It'll also include the libraries for common data-science utilities used to represent the reseults and post-processing for visualizations on a Streamlit website.

### Step 2: \`Touch\` or Create Empty Config Files

The environment is defined by three key files in the root directory. Make these files:

1. requirements.txt
2. Dockerfile
3. docker-compose.yml

### Step 3: Setup Dependencies

Make a requirements.txt file in the project root directory.

{% code title="requirements.txt" %}
```
# Core libraries for interacting with the LLM and data processing
ollama
pandas
numpy

# Libraries for creating a web-based dashboard/UI
streamlit
matplotlib
```
{% endcode %}

### Step 4: Create the `Dockerfile`

Next, we'll create the blueprint for our custom Python environment. This creates the step-by-step instructions Docker uses to build the Python container.&#x20;

The syntax for these are `INSTRUCTION arguments` and conventionally instructions are for them to be uppercase to distinguish them from args more easily. See `docs.docker.com/reference/dockerfile` for a review.&#x20;

```docker
# Get base image.
FROM python:3.11-slim

run echo "Launching MC's Docker Container for LLMs..."

# Setup ENV - subsequent commands like COPY and RUN will execute here.
WORKDIR /app

# Install Dependencies to the current working dir (/app)
COPY requirements.txt .

# Run pip install command inside the container
RUN pip install --no-cache-dir -r requirements.txt

# Expose Streamlit to a port
EXPOSE 8501
```





## Works Cited & Helpful Resources

### Dockerfile Documentation

{% embed url="https://docs.dockerfile.com/reference/dockerfile" %}

### Private-Hosting Video

This video was my 'starting point' that'll tell you how to get it running on Docker Desktop. I turned it into a yaml file to put them in nested containers under one shebang.&#x20;

{% embed url="https://www.youtube.com/watch?v=y5-6qww8uKk" %}

### Notebook LLM

I'm also exploring NotebookLLM to make these docs better.&#x20;

{% embed url="https://notebooklm.google.com/notebook/8a6af04e-cb44-4bd0-9688-f9f0dd53d1f8" %}

Unfortunately, some work is split between this notebook, OneNote (Work), and the above Notebook LLM; however, I plan to make this the "final" version.&#x20;

## Off-Topic LLM Dance Experiment

> "Dance Experiment": Interest in decerning shared intent. Main piece is to say "i make a decision" and I anticipate the decision you're going to make and then I make a decision based on the anticipated thing. Take a blotto game, but the object of the game is not to win, but the objective is to be as closely aligned as possible as a part of the LLM. Let's suppose that I have three fronts, A, B, and C, and I need to allocate resources at any given time. Let's say I put 90A, 90B, 90C.... very simple initial example. The LLM should learn that if I should invest in this other prompt and allocating "correctly" and if so, the delta btw the two is zero meaning it maximized the shared intent correctly. Ideally, there'll be some functional thing that this all will represent.&#x20;
>
> It's trying to understand intnet. If it understands your intent of how it'll allocate resources, then there is maximal alignment between the team. Think of it like we're doing a dance together, right? And we're going a certain way. And the model expects you to do this, and you do that, and it's all aligned/dandy. So it'll know what you'll do next. That's an indication of shared intent.&#x20;
>
> The nice thing about blotto/plotto is you can definitelvly show the degree of alignment. Add some semantic understanding that, maybe a piece of context, and then figure out what you both think/anticipate given the rules & piece of information. Then you and the LLM could see if you're interperting the context in the same way.
>
> It's a little dependent upon who is influencing who. In this case, it'll be the human agent. You described it as "his objective was to keep the confederacy stationary" or union thing. And what he did was move all the way around to push them in there. The slight adjustment is that you had an army that was stationed between Shandoah and DC to protect DC and they send off a small group to fend off stonewall jackson. But then, they kept losing. And so, they couldn't move the big army away from DC because they couldn't leave DC unprotected. But the intention was to move that army to attack ??. But because stonewall jackson kept having problems and couldn't be defeated, they couldn't move that army...&#x20;
>
> By virtue of numbers, show if we agree or disagree.&#x20;

.



